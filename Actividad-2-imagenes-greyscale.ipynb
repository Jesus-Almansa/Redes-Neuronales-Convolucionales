{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4078,
     "status": "ok",
     "timestamp": 1684345131354,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "bAZ7bv9rgDUE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 12:23:20.091489: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-19 12:23:20.093082: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-19 12:23:20.125744: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-19 12:23:20.126314: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 12:23:20.693331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import keras\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7088,
     "status": "ok",
     "timestamp": 1684345138437,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "IfEK6tdngI6p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar (child): /root/.keras/datasets/simpsons_train.tar.gz: No se puede efectuar open: Permiso denegado\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n",
      "tar (child): /root/.keras/datasets/simpsons_test.tar.gz: No se puede efectuar open: Permiso denegado\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "# Primero, bajamos los datos de entrenamiento\n",
    "keras.utils.get_file(fname=\"simpsons_train.tar.gz\", \n",
    "                     origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60\")\n",
    "\n",
    "# Descomprimimos el archivo\n",
    "!tar -xzf /root/.keras/datasets/simpsons_train.tar.gz -C /root/.keras/datasets\n",
    "\n",
    "\n",
    "# Hacemos lo mismo con los datos de test\n",
    "keras.utils.get_file(fname=\"simpsons_test.tar.gz\", \n",
    "                     origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8\")\n",
    "!tar -xzf /root/.keras/datasets/simpsons_test.tar.gz -C /root/.keras/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1684345138438,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "5FhI6rc5gI_U"
   },
   "outputs": [],
   "source": [
    "# Esta variable contiene un mapeo de número de clase a personaje.\n",
    "# Utilizamos sólo los 18 personajes del dataset que tienen más imágenes.\n",
    "MAP_CHARACTERS = {\n",
    "    0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson',\n",
    "    3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n",
    "    7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson', \n",
    "    11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak', \n",
    "    14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'\n",
    "}\n",
    "\n",
    "# Vamos a standarizar todas las imágenes a tamaño 64x64\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684345138438,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "PYUQPIjMgJCe"
   },
   "outputs": [],
   "source": [
    "def load_train_set(dirname, map_characters, verbose=True):\n",
    "    \"\"\"Esta función carga los datos de training en imágenes.\n",
    "    \n",
    "    Como las imágenes tienen tamaños distintas, utilizamos la librería opencv\n",
    "    para hacer un resize y adaptarlas todas a tamaño IMG_SIZE x IMG_SIZE.\n",
    "    \n",
    "    Args:\n",
    "        dirname: directorio completo del que leer los datos\n",
    "        map_characters: variable de mapeo entre labels y personajes\n",
    "        verbose: si es True, muestra información de las imágenes cargadas\n",
    "     \n",
    "    Returns:\n",
    "        X, y: X es un array con todas las imágenes cargadas con tamaño\n",
    "                IMG_SIZE x IMG_SIZE\n",
    "              y es un array con las labels de correspondientes a cada imagen\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for label, character in map_characters.items():        \n",
    "        files = os.listdir(os.path.join(dirname, character))\n",
    "        images = [file for file in files if file.endswith(\"jpg\")]\n",
    "        if verbose:\n",
    "          print(\"Leyendo {} imágenes encontradas de {}\".format(len(images), character))\n",
    "        for image_name in images:\n",
    "            image = cv2.imread(os.path.join(dirname, character, image_name))\n",
    "            X_train.append(cv2.resize(image,(IMG_SIZE, IMG_SIZE)))\n",
    "            y_train.append(label)\n",
    "    return np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684345138438,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "lwpNn_UJgJFY"
   },
   "outputs": [],
   "source": [
    "def load_test_set(dirname, map_characters, verbose=True):\n",
    "    \"\"\"Esta función funciona de manera equivalente a la función load_train_set\n",
    "    pero cargando los datos de test.\"\"\"\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    reverse_dict = {v: k for k, v in map_characters.items()}\n",
    "    for filename in glob.glob(dirname + '/*.*'):\n",
    "        char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n",
    "        if char_name in reverse_dict:\n",
    "            image = cv2.imread(filename)\n",
    "            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "            X_test.append(image)\n",
    "            y_test.append(reverse_dict[char_name])\n",
    "    if verbose:\n",
    "        print(\"Leídas {} imágenes de test\".format(len(X_test)))\n",
    "    return np.array(X_test), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39012,
     "status": "ok",
     "timestamp": 1684345177443,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "hjO9gj-rgJH2",
    "outputId": "31fa560b-3ea4-49bb-8320-00a1f117870a"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/root/.keras/datasets/simpsons/abraham_grampa_simpson'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m DATASET_TRAIN_PATH_COLAB \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/.keras/datasets/simpsons\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m DATASET_TEST_PATH_COLAB \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/.keras/datasets/simpsons_testset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_train_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_TRAIN_PATH_COLAB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAP_CHARACTERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m X_t, y_t \u001b[38;5;241m=\u001b[39m load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mload_train_set\u001b[0;34m(dirname, map_characters, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m y_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, character \u001b[38;5;129;01min\u001b[39;00m map_characters\u001b[38;5;241m.\u001b[39mitems():        \n\u001b[0;32m---> 20\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharacter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     images \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/root/.keras/datasets/simpsons/abraham_grampa_simpson'"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos. Si no estás trabajando en colab, cambia los paths por\n",
    "# los de los ficheros donde hayas descargado los datos.\n",
    "DATASET_TRAIN_PATH_COLAB = \"/root/.keras/datasets/simpsons\"\n",
    "DATASET_TEST_PATH_COLAB = \"/root/.keras/datasets/simpsons_testset\"\n",
    "\n",
    "X, y = load_train_set(DATASET_TRAIN_PATH_COLAB, MAP_CHARACTERS)\n",
    "X_t, y_t = load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1684345177444,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "EGeDc4hIgJLE"
   },
   "outputs": [],
   "source": [
    "# Vamos a barajar aleatoriamente los datos. Esto es importante ya que si no\n",
    "# lo hacemos y, por ejemplo, cogemos el 20% de los datos finales como validation\n",
    "# set, estaremos utilizando solo un pequeño número de personajes, ya que\n",
    "# las imágenes se leen secuencialmente personaje a personaje.\n",
    "perm = np.random.permutation(len(X))\n",
    "X, y = X[perm], y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 1861,
     "status": "ok",
     "timestamp": 1684345179301,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "pZSBpbBIgJNq",
    "outputId": "ff89c9cd-4785-4b69-9b3a-9c578e6d860d"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_t[2]) # recordad que siempre es preferible trabajar en blanco y negro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1684345179302,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "9vZpEYFXcFa5",
    "outputId": "0a5ca964-38bb-46b5-bbb9-2e350962739b"
   },
   "outputs": [],
   "source": [
    "print(f'Shape X: {X.shape}')\n",
    "print(f'Shape y: {y.shape}')\n",
    "print(f'Shape X_t: {X_t.shape}')\n",
    "print(f'Shape y_t: {y_t.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uBP7LPic5VRx"
   },
   "source": [
    "# CAMBIAR A BLANCO Y NEGRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1684345179303,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "npnet4GMTlN6"
   },
   "outputs": [],
   "source": [
    "# Convertir imagenes de entrenamiento a blanco y negro\n",
    "\n",
    "X_grayscale = np.empty((X.shape[0], X.shape[1], X.shape[2]), dtype=np.uint8)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X_grayscale[i] = cv2.cvtColor(X[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Convertir imagenes de test a blanco y negro\n",
    "\n",
    "X_t_grayscale = np.empty((X_t.shape[0], X_t.shape[1], X_t.shape[2]), dtype=np.uint8)\n",
    "\n",
    "for i in range(X_t.shape[0]):\n",
    "    X_t_grayscale[i] = cv2.cvtColor(X_t[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1684345179925,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "iYo-CjQzdXvU",
    "outputId": "a2520cc9-68af-407e-f65b-85cb89e1af32"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_t_grayscale[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1684345179925,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "fYhjCI3qdTXc",
    "outputId": "15878f29-ac13-479f-db74-17a44d79b229"
   },
   "outputs": [],
   "source": [
    "print(f'Shape X_grayscale: {X_grayscale.shape}')\n",
    "print(f'Shape X_t_grayscale: {X_t_grayscale.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1684345179925,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "Gy1eNFGJUbme"
   },
   "outputs": [],
   "source": [
    "X_grayscale_norm = X_grayscale.astype('float32') / 255.\n",
    "X_t_grayscale_norm = X_t_grayscale.astype('float32') / 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1684345179926,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "BrJaJHbOUajn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_grayscale_norm, y,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1684345179926,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "zaJ8YbL8c-oE",
    "outputId": "43af92cf-ae0f-469f-e947-d7b03dd674f1"
   },
   "outputs": [],
   "source": [
    "print(f'Shape X_train: {X_train.shape}')\n",
    "print(f'Shape y_train: {y_train.shape}')\n",
    "print(f'Shape X_valid: {X_valid.shape}')\n",
    "print(f'Shape y_valid: {y_valid.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yjwFas-5gcZt"
   },
   "source": [
    "Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1684345179926,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "pGEt1az-gJQh"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1684345179926,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "oINIVxAxgtA0"
   },
   "outputs": [],
   "source": [
    "# y_train_cat = to_categorical(y_train, num_classes=18)\n",
    "# y_valid_cat = to_categorical(y_valid, num_classes=18)\n",
    "# y_t_cat = to_categorical(y_t, num_classes=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "error",
     "timestamp": 1684345179927,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "Zhf8DjUwdrtc",
    "outputId": "37ff5f9a-7f5c-419f-96ea-dd5f59f9168c"
   },
   "outputs": [],
   "source": [
    "# print(f'Shape y_train_cat: {y_train_cat.shape}')\n",
    "# print(f'Shape y_valid_cat: {y_valid_cat.shape}')\n",
    "# print(f'Shape y_t_cat: {y_t_cat.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RVxRJhotymtZ"
   },
   "source": [
    "**Comentarios del modelo:**   \n",
    "\n",
    "*   Ha mejorado con 3 capas conv \n",
    "*   Dropout 0.5 mejor que 0.2 \n",
    "*   Con adamax parece que va algo mejor.\n",
    "*   Dense(128, activation='relu') ->80%\n",
    "*   batch_size = 64 -> 0.8136\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194788,
     "status": "ok",
     "timestamp": 1684345616460,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "iMN2Obd3gJZW",
    "outputId": "987b8c0f-331e-488a-f834-310777ccfed4"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "paciencia = 20\n",
    "\n",
    "# EarlyStop si durante x epoch no se consigue ninguna mejora en val_accuracy\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=paciencia)\n",
    "\n",
    "# Imprimir mensaje indicando que no se han conseguido mejoras durante x epoch.\n",
    "class ImprimirMensajeCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.model.stop_training:\n",
    "            print(f\"El entrenamiento ha sido detenido, val_accuracy no ha mejorado durante {paciencia} epoch.\")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "        epochs=200,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=1, \n",
    "        batch_size=256,\n",
    "        callbacks=[early_stopping, ImprimirMensajeCallback()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1684345666280,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "9mVen28AgtMZ",
    "outputId": "c252a150-67e5-4612-dd5d-ca7d4d5fe02b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1684343857242,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "3ShumynNsRoy",
    "outputId": "e4c9ac87-452f-4b36-b428-d7f54fa78989"
   },
   "outputs": [],
   "source": [
    "    # score = model.score(X_test, y_test)\n",
    "    # pred = model.predict(X_test)\n",
    "    # confusionmatrix = confusion_matrix(y_test,pred)\n",
    "    # classificationreport = classification_report(y_test, pred)\n",
    "\n",
    "    # print(f\"Score: {score} \\n\")\n",
    "    # print(\"Matriz de confusión:\")\n",
    "    # print(confusionmatrix)\n",
    "    # print(\"\\nClassification Report: \")\n",
    "    # print(classificationreport) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 835,
     "status": "ok",
     "timestamp": 1684345685227,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "v20HtfPUemEG",
    "outputId": "f5ae03c5-a990-4e5a-c5c3-ddc4ccd3a672"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de datos de prueba\n",
    "test_loss, test_acc = model.evaluate(X_t_grayscale_norm, y_t)\n",
    "\n",
    "# Mostrar la precisión y la pérdida del modelo en el conjunto de datos de test\n",
    "print(f'\\n El accuracy obtenido es: {round(test_acc, 5)}')\n",
    "print(f'\\n El loss: {round(test_loss, 5)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0ggNNu-cQCYU"
   },
   "source": [
    "# **Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ahjtan5QAht"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paciencia = 20\n",
    "\n",
    "# EarlyStop si durante x epoch no se consigue ninguna mejora en val_accuracy\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=paciencia)\n",
    "\n",
    "# Imprimir mensaje indicando que no se han conseguido mejoras durante x epoch.\n",
    "class ImprimirMensajeCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.model.stop_training:\n",
    "            print(f\"El entrenamiento ha sido detenido, val_accuracy no ha mejorado durante {paciencia} epoch.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CB0-R0g9Sz31"
   },
   "source": [
    "# Modelo CNN definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tpuvBO7SyUU"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6zGKxM6Am6"
   },
   "source": [
    "# Pruebas CNN BATCH SIZE [32,64,128,256,512]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 441599,
     "status": "ok",
     "timestamp": 1684336535602,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "epgKlBtIIVcX",
    "outputId": "7155d00e-ca0c-46e9-b38c-b5b8686427dd"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
    "\n",
    "for i in [32,64,128,256,512]:\n",
    "  print('\\n')\n",
    "  print('-------------------------------------')\n",
    "  print('-------------------------------------')\n",
    "  print(f'Prueba con Batch Size: {i}')\n",
    "\n",
    "  history = model.fit(X_train, y_train,\n",
    "          epochs=200,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          verbose=0, \n",
    "          batch_size = i,\n",
    "          callbacks=[early_stopping, ImprimirMensajeCallback()])\n",
    "  \n",
    "\n",
    "\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend(loc=0)\n",
    "  plt.figure()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  # Evaluar el modelo en el conjunto de datos de prueba\n",
    "  print(f'\\n')\n",
    "  print(f'Métricas con dataset de validación:')\n",
    "\n",
    "  valid_loss, valid_acc = model.evaluate(X_valid, y_valid)\n",
    "\n",
    "  print(f'\\n')\n",
    "  print(f'Métricas con dataset de test:')\n",
    "\n",
    "  test_loss, test_acc = model.evaluate(X_t_grayscale_norm, y_t)\n",
    "\n",
    "  print(f'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "m-UhDYaSJmnA"
   },
   "source": [
    "# Conclusión: Todas se comportan parecido\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nNuSbAXAIub-"
   },
   "source": [
    "# **PRUEBAS CNN OPTIMIZER [\"sgd\", \"rmsprop\", \"adam\", \"adagrad\", \"adadelta\", \"adamax\", \"nadam\", \"ftrl\"]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 907633,
     "status": "ok",
     "timestamp": 1684335226407,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "-GGul3MxIwi2",
    "outputId": "c57a3194-b896-4e4e-a250-b6082252060d"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# Lista de optimizadores que se van a utilizar durante las pruebas\n",
    "lista_optimizadores = [\"sgd\", \"rmsprop\", \"adam\", \"adagrad\", \"adadelta\", \"adamax\", \"nadam\", \"ftrl\"]\n",
    "\n",
    "for optimizador in lista_optimizadores:\n",
    "  print('\\n')\n",
    "  print('-------------------------------------')\n",
    "  print('-------------------------------------')\n",
    "  print('\\n')\n",
    "  print(f' Pruebas con optimizador: {optimizador}')\n",
    "\n",
    "\n",
    "  model.compile(loss = 'sparse_categorical_crossentropy', optimizer=optimizador, metrics=['accuracy'])\n",
    "\n",
    "  history = model.fit(X_train, y_train,\n",
    "          epochs=200,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          verbose=0, \n",
    "          batch_size = 32,\n",
    "          callbacks=[early_stopping, ImprimirMensajeCallback()])\n",
    "\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend(loc=0)\n",
    "  plt.figure()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  # Evaluar el modelo en el conjunto de datos de prueba\n",
    "  print(f'\\n')\n",
    "  print(f'Métricas con dataset de validación:')\n",
    "\n",
    "  valid_loss, valid_acc = model.evaluate(X_valid, y_valid)\n",
    "\n",
    "  print(f'\\n')\n",
    "  print(f'Métricas con dataset de test:')\n",
    "\n",
    "  test_loss, test_acc = model.evaluate(X_t_grayscale_norm, y_t)\n",
    "\n",
    "  print(f'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "b0VTpg_LTmp2"
   },
   "source": [
    "# ANN (Con hiperparámetros seleccionados en CNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz2EpFz3VkY8"
   },
   "source": [
    "Función para complilar, fit y evaluar el modelo.   \n",
    "Se muestra solo una evaluación con dataset de validadación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sKkZdalVQR8"
   },
   "outputs": [],
   "source": [
    "def compile_fit_evaluate(model):\n",
    "  model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
    "\n",
    "  history = model.fit(X_train, y_train,\n",
    "          epochs=200,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          verbose=0, \n",
    "          batch_size = 32,\n",
    "          callbacks=[early_stopping, ImprimirMensajeCallback()])\n",
    "\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend(loc=0)\n",
    "  plt.figure()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  # Evaluar el modelo en el conjunto de datos de prueba\n",
    "  print(f'\\n')\n",
    "  print(f'Métricas con dataset de validación:')\n",
    "\n",
    "  valid_loss, valid_acc = model.evaluate(X_valid, y_valid)\n",
    "\n",
    "  print(f'\\n')\n",
    "  print(f'Métricas con dataset de test:')\n",
    "\n",
    "  test_loss, test_acc = model.evaluate(X_t_grayscale_norm, y_t)\n",
    "\n",
    "  print(f'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 265946,
     "status": "ok",
     "timestamp": 1684337727412,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "l97Wp6neTqF3",
    "outputId": "e2efc59e-b900-4dab-cf05-5c25a86f60c1"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[64,64]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "compile_fit_evaluate(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 255190,
     "status": "ok",
     "timestamp": 1684338088993,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "X_izWRQ-WoSN",
    "outputId": "9ac9b76a-7338-496f-be25-b73928c5b1ec"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[64,64]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "compile_fit_evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 217552,
     "status": "ok",
     "timestamp": 1684338306541,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "WTZ7QBDxWuhW",
    "outputId": "050a9a0d-691d-45f6-b282-fa730b7df61b"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[64,64]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "compile_fit_evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 221598,
     "status": "ok",
     "timestamp": 1684338599466,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "Cv35_GmNY7rA",
    "outputId": "6532cece-5b98-4fb8-bb68-5bbc9a7da850"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[64,64]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "compile_fit_evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 173388,
     "status": "ok",
     "timestamp": 1684338969713,
     "user": {
      "displayName": "salvelpr",
      "userId": "03936313709350824429"
     },
     "user_tz": -120
    },
    "id": "x5WNKXsZagdz",
    "outputId": "5f610a34-2209-40bd-90d0-47d7ec2f5b67"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[64,64]),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "compile_fit_evaluate(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lvmp3XHOYe0I"
   },
   "source": [
    "Comentar que con los mismos hiperparámetros los resultados son peores.   \n",
    "Hace falta ajustarlos"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
